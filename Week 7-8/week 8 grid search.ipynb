{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa4b605",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "The majority of machine learning models contain parameters that can be adjusted to vary how the model learns. For example, the logistic regression model, from sklearn, has a parameter C that controls regularization,which affects the complexity of the model.\n",
    "\n",
    "Regularization is a method to constraint the model to fit our data accurately and not overfit. It can also be thought of as penalizing unnecessary complexity in our model. For more information about regularization, see https://towardsdatascience.com/regularization-what-why-when-and-how-d4a329b6b27f\n",
    "\n",
    "How do we pick the best value for C? The best value is dependent on the data used to train the model.\n",
    "\n",
    "### How does it work?\n",
    "\n",
    "One method is to try out different values and then pick the value that gives the best score. This technique is known as a grid search. If we had to select the values for two or more parameters, we would evaluate all combinations of the sets of values thus forming a grid of values.\n",
    "\n",
    "Before we get into the example it is good to know what the parameter we are changing does. Higher values of C tell the model, the training data resembles real world information, place a greater weight on the training data. While lower values of C do the opposite.\n",
    "\n",
    "### Using Default Parameters\n",
    "\n",
    "First let's see what kind of results we can generate without a grid search using only the base parameters.\n",
    "\n",
    "To get started we must first load in the dataset we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10e32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "# For more information about iris dataset see, https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html#\n",
    "#print (iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750234c",
   "metadata": {},
   "source": [
    "Next in order to create the model we must have a set of independent variables X and a dependant variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149566ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e687319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (X)\n",
    "#print (\"\\n\\n\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc91631",
   "metadata": {},
   "source": [
    "Now we will load the logistic model for classifying the iris flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742a317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea508b",
   "metadata": {},
   "source": [
    "Creating the model, setting max_iter to a higher value to ensure that the model finds a result.\n",
    "\n",
    "Keep in mind the default value for C in a logistic regression model is 1, we will compare this later.\n",
    "\n",
    "For more information about the parameters of logistic regression like C and max_iter see, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "In the example below, we look at the iris data set and try to train a model with varying values for C in logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1b7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(max_iter = 10000) # max_iter is the maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "# After we create the model, we must fit the model to the data.\n",
    "\n",
    "logit.fit(X,y)\n",
    "\n",
    "# To evaluate the model we run the score method.\n",
    "\n",
    "print(logit.score(X,y)) # score(X, y[, sample_weight]) Return the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd19ef8",
   "metadata": {},
   "source": [
    "With the default setting of C = 1, we achieved a score of 0.973.\n",
    "\n",
    "Let's see if we can do any better than 0.973 by implementing a grid search with different values of C.\n",
    "\n",
    "### Implementing Grid Search\n",
    "\n",
    "We will follow the same steps of before, except this time we will set a range of values for C.\n",
    "\n",
    "Knowing which values to set for the searched parameters will take a combination of domain knowledge and practice.\n",
    "\n",
    "Since the default value for C is 1, we will set a range of values surrounding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026d14f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.9733333333333334, 0.98, 0.98, 0.9866666666666667, 0.9866666666666667]\n"
     ]
    }
   ],
   "source": [
    "C = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "\n",
    "# Next we will create a for loop to change out the values of C and evaluate the model with each change.\n",
    "\n",
    "# First we will create an empty list to store the score within.\n",
    "\n",
    "scores = []\n",
    "\n",
    "# To change the values of C we must loop over the range of values and update the parameter each time.\n",
    "\n",
    "for choice in C:\n",
    "  logit.set_params(C=choice) # Set the parameters of this estimator.\n",
    "  logit.fit(X, y)\n",
    "  scores.append(logit.score(X, y))\n",
    "\n",
    "# With the scores stored in a list, we can evaluate what the best choice of C is.\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e064a3f",
   "metadata": {},
   "source": [
    "### Results Explained\n",
    "\n",
    "We can see that the lower values of C performed worse than the base parameter of 1. However, as we increased the value of C to 1.75 the model experienced increased accuracy.\n",
    "\n",
    "It seems that increasing C beyond this amount does not help increase model accuracy.\n",
    "\n",
    "### Note on Best Practices\n",
    "\n",
    "We scored our logistic regression model by using the same data that was used to train it. If the model corresponds too closely to that data, it may not be great at predicting unseen data. This statistical error is known as over fitting.\n",
    "\n",
    "To avoid being misled by the scores on the training data, we can put aside a portion of our data and use it specifically for the purpose of testing the model. Refer to the lecture on train/test splitting to avoid being misled and overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
