{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "When adjusting models we are aiming to increase overall model performance on unseen data. Hyperparameter tuning can lead to much better performance on test sets. However, optimizing parameters to the test set can lead information leakage causing the model to preform worse on unseen data. We can perform cross validation to correct this.\n",
    "\n",
    "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters are learned.\n",
    "\n",
    "To better understand Cross Validation, we will be performing different methods on the iris dataset. Let us first load in and separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "#print (X)\n",
    "\n",
    "#print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many methods for cross validation, let's start by looking at k-fold cross validation.\n",
    "\n",
    "### K-Fold\n",
    "\n",
    "The training data used in the model is split into k number of smaller sets to be used to validate the model. The model is then trained on k-1 folds of training set. The remaining fold is then used as a validation set to evaluate the model.\n",
    "\n",
    "K-Folds cross-validator provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default). Each fold is then used once as a validation while the k - 1 remaining folds form the training set.\n",
    "\n",
    "As we will be trying to classify different species of iris flowers, we will need to import a classifier model. For this exercise we will be using a DecisionTreeClassifier. We will also need to import CV modules from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1.         1.         0.83333333 0.93333333 0.8       ]\n",
      "Average Cross Validation Score:  0.9133333333333333\n",
      "Number of Cross Validation Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# With the data loaded we can now create and fit a model for evaluation.\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42) # To obtain a deterministic behaviour during fitting,\n",
    "                                              # random_state has to be fixed to an integer.\n",
    "    \n",
    "# Now let's evaluate our model and see how it performs on each k-fold.\n",
    "\n",
    "k_folds = KFold (n_splits = 5)\n",
    "\n",
    "scores = cross_val_score (clf, X, y, cv = k_folds) # Evaluate a score by cross-validation.\n",
    "                                                   \n",
    "                        # clf is the estimator\n",
    "                        # X: The data to fit. Can be a list, or an array.\n",
    "                        # y: The target variable to try to predict in the case of supervised learning.\n",
    "                        # cv: Determines the cross-validation splitting strategy.\n",
    "                        # Returns an array of scores of the estimator for each run of the cross validation.\n",
    "                    \n",
    "# It is also good pratice to see how Cross Validation performed overall by averaging the scores for all folds.\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average Cross Validation Score: \", scores.mean())\n",
    "print(\"Number of Cross Validation Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following link has useful inormation about cross validation:    \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold\n",
    "\n",
    "In cases where classes are imbalanced we need a way to account for the imbalance in both the train and validation sets. To do so we can stratify the target classes, meaning that both sets will have an equal proportion of all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.96666667 0.96666667 0.9        0.93333333 1.        ]\n",
      "Average CV Score:  0.9533333333333334\n",
      "Number of CV Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sk_folds = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = sk_folds)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the number of folds is the same, the average CV increases from the basic k-fold when making sure there is stratified classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out (LOO)\n",
    "\n",
    "Instead of selecting the number of splits in the training data set like k-fold, LeaveOneOut utilizes 1 observation to validate and n-1 observations to train. This method is an exaustive technique.\n",
    "\n",
    "LeaveOneOut (or LOO) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. This cross-validation procedure does not waste much data as only one sample is removed from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Average CV Score:  0.94\n",
      "Number of CV Scores used in Average:  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = loo)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the number of cross validation scores performed is equal to the number of observations in the dataset. In this case there are 150 observations in the iris dataset.\n",
    "\n",
    "The average CV score is 94%.\n",
    "\n",
    "### Leave-P-Out (LPO)\n",
    "\n",
    "Leave-P-Out is simply a nuanced diffence to the Leave-One-Out idea, in that we can select the number of p to use in our validation set.\n",
    "\n",
    "LeavePOut is very similar to LeaveOneOut as it creates all the possible training/test sets by removing p samples from the complete set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1. 1. 1. ... 1. 1. 1.]\n",
      "Average CV Score:  0.9382997762863534\n",
      "Number of CV Scores used in Average:  11175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "lpo = LeavePOut(p=2)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = lpo)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this is an exhaustive method we many more scores being calculated than Leave-One-Out, even with a p = 2, yet it achieves roughly the same average CV score.\n",
    "\n",
    "### Shuffle Split\n",
    "\n",
    "Unlike KFold, ShuffleSplit leaves out a percentage of the data, not to be used in the train or validation sets. To do so we must decide what the train and test sizes are, as well as the number of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.91111111 0.91111111 0.93333333 0.97777778 0.97777778]\n",
      "Average CV Score:  0.9422222222222223\n",
      "Number of CV Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(train_size=0.6, test_size=0.3, n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = ss)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ending Notes\n",
    "\n",
    "These are just a few of the CV methods that can be applied to models. There are many more cross validation classes. Check out sklearns cross validation for more CV options at the following link \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
